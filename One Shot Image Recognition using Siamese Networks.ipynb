{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "One_shot_learning_on_omniglot.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9NVrwkzPh7_"
      },
      "source": [
        "%matplotlib inline\n",
        "import os\n",
        "import cv2\n",
        "import sys\n",
        "import time\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy.random as rng\n",
        "from imageio import imread\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import shuffle\n",
        "from keras.optimizers import Adam\n",
        "from keras.regularizers import l2\n",
        "from keras.models import Sequential\n",
        "from keras.engine.topology import Layer\n",
        "from keras.layers.merge import Concatenate\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.core import Lambda, Flatten, Dense\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmHVlUFzQ-h-",
        "outputId": "9fc711c8-10e7-4a8d-f1cc-9cdfcc1227e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/brendenlake/omniglot/master/python/images_background.zip\n",
        "!wget https://raw.githubusercontent.com/brendenlake/omniglot/master/python/images_evaluation.zip\n",
        "!unzip images_background.zip >/dev/null\n",
        "!unzip images_evaluation.zip >/dev/null\n",
        "!rm images_background.zip images_evaluation.zip\n",
        "!mkdir data\n",
        "!mkdir weights"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-14 08:29:07--  https://raw.githubusercontent.com/brendenlake/omniglot/master/python/images_background.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9464212 (9.0M) [application/zip]\n",
            "Saving to: ‘images_background.zip’\n",
            "\n",
            "\rimages_background.z   0%[                    ]       0  --.-KB/s               \rimages_background.z 100%[===================>]   9.03M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2020-11-14 08:29:07 (122 MB/s) - ‘images_background.zip’ saved [9464212/9464212]\n",
            "\n",
            "--2020-11-14 08:29:07--  https://raw.githubusercontent.com/brendenlake/omniglot/master/python/images_evaluation.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6462886 (6.2M) [application/zip]\n",
            "Saving to: ‘images_evaluation.zip’\n",
            "\n",
            "images_evaluation.z 100%[===================>]   6.16M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2020-11-14 08:29:07 (91.2 MB/s) - ‘images_evaluation.zip’ saved [6462886/6462886]\n",
            "\n",
            "replace images_background/Alphabet_of_the_Magi/character01/0709_01.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: a\n",
            "error:  invalid response [a]\n",
            "replace images_background/Alphabet_of_the_Magi/character01/0709_01.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "replace images_evaluation/Angelic/character01/0965_01.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "mkdir: cannot create directory ‘data’: File exists\n",
            "mkdir: cannot create directory ‘weights’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyL7Odl-Ph8F"
      },
      "source": [
        "train_folder = \"./images_background/\"\n",
        "val_folder = './images_evaluation/'\n",
        "save_path = './data/'"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9_nW22UPh8H"
      },
      "source": [
        "def loadimgs(path,n = 0):\n",
        "    '''\n",
        "    path => Path of train directory or test directory\n",
        "    '''\n",
        "    X =[]\n",
        "    y = []\n",
        "    cat_dict = {}\n",
        "    lang_dict = {}\n",
        "    curr_y = n\n",
        "    # we load every alphabet seperately so we can isolate them later\n",
        "    for alphabet in os.listdir(path):\n",
        "        print(\"loading alphabet: \" + alphabet)\n",
        "        lang_dict[alphabet] = [curr_y,None]\n",
        "        alphabet_path = os.path.join(path,alphabet)\n",
        "        # every letter/category has it's own column in the array, so  load seperately\n",
        "        for letter in os.listdir(alphabet_path):\n",
        "            cat_dict[curr_y] = (alphabet, letter)\n",
        "            category_images=[]\n",
        "            letter_path = os.path.join(alphabet_path, letter)\n",
        "            # read all the images in the current category\n",
        "            for filename in os.listdir(letter_path):\n",
        "                image_path = os.path.join(letter_path, filename)\n",
        "                image = imread(image_path)\n",
        "                category_images.append(image)\n",
        "                y.append(curr_y)\n",
        "            try:\n",
        "                X.append(np.stack(category_images))\n",
        "            # edge case  - last one\n",
        "            except ValueError as e:\n",
        "                print(e)\n",
        "                print(\"error - category_images:\", category_images)\n",
        "            curr_y += 1\n",
        "            lang_dict[alphabet][1] = curr_y - 1\n",
        "    y = np.vstack(y)\n",
        "    X = np.stack(X)\n",
        "    return X,y,lang_dict"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFuj8prgPh8K"
      },
      "source": [
        "### Loading the train images into tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sTAGXpcPh8N",
        "outputId": "856cb022-a31c-47a9-af3c-e833710f9091",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X,y,c=loadimgs(train_folder)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading alphabet: Hebrew\n",
            "loading alphabet: Armenian\n",
            "loading alphabet: Malay_(Jawi_-_Arabic)\n",
            "loading alphabet: Japanese_(katakana)\n",
            "loading alphabet: Anglo-Saxon_Futhorc\n",
            "loading alphabet: Burmese_(Myanmar)\n",
            "loading alphabet: Grantha\n",
            "loading alphabet: Asomtavruli_(Georgian)\n",
            "loading alphabet: Tagalog\n",
            "loading alphabet: Cyrillic\n",
            "loading alphabet: Futurama\n",
            "loading alphabet: Ojibwe_(Canadian_Aboriginal_Syllabics)\n",
            "loading alphabet: Inuktitut_(Canadian_Aboriginal_Syllabics)\n",
            "loading alphabet: Arcadian\n",
            "loading alphabet: Alphabet_of_the_Magi\n",
            "loading alphabet: Tifinagh\n",
            "loading alphabet: Early_Aramaic\n",
            "loading alphabet: Japanese_(hiragana)\n",
            "loading alphabet: Gujarati\n",
            "loading alphabet: Mkhedruli_(Georgian)\n",
            "loading alphabet: Latin\n",
            "loading alphabet: Balinese\n",
            "loading alphabet: Bengali\n",
            "loading alphabet: Korean\n",
            "loading alphabet: Greek\n",
            "loading alphabet: Blackfoot_(Canadian_Aboriginal_Syllabics)\n",
            "loading alphabet: Braille\n",
            "loading alphabet: Sanskrit\n",
            "loading alphabet: N_Ko\n",
            "loading alphabet: Syriac_(Estrangelo)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBE0wcVjB6WV",
        "outputId": "02c28601-b393-44ba-9884-ca5bc18cd695",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"We'll be using 964 characters for training the model out of 1632 characters,\\n and each character has 20 samples per character \\nhaving dimensions of 105x105, therefore its shape will be,\\n \", X.shape, \"\\n\\nAnd for each sample, there's the category (964*20), therefore its dimensions are:\\n\",y.shape)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We'll be using 964 characters for training the model out of 1632 characters,\n",
            " and each character has 20 samples per character \n",
            "having dimensions of 105x105, therefore its shape will be,\n",
            "  (964, 20, 105, 105) \n",
            "\n",
            "And for each sample, there's the category (964*20), therefore its dimensions are:\n",
            " (19280, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gq2biPXlGH9s",
        "outputId": "28ef67fd-25d9-43c3-a196-1571507a2ef5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "c.keys()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['Hebrew', 'Armenian', 'Malay_(Jawi_-_Arabic)', 'Japanese_(katakana)', 'Anglo-Saxon_Futhorc', 'Burmese_(Myanmar)', 'Grantha', 'Asomtavruli_(Georgian)', 'Tagalog', 'Cyrillic', 'Futurama', 'Ojibwe_(Canadian_Aboriginal_Syllabics)', 'Inuktitut_(Canadian_Aboriginal_Syllabics)', 'Arcadian', 'Alphabet_of_the_Magi', 'Tifinagh', 'Early_Aramaic', 'Japanese_(hiragana)', 'Gujarati', 'Mkhedruli_(Georgian)', 'Latin', 'Balinese', 'Bengali', 'Korean', 'Greek', 'Blackfoot_(Canadian_Aboriginal_Syllabics)', 'Braille', 'Sanskrit', 'N_Ko', 'Syriac_(Estrangelo)'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31EpjdmoGLrL",
        "outputId": "4a3b8c5e-8f3f-4076-d7ac-940d0f75ad21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('This holds the indexes of the corresponding chatacters in the c.keys()\\n', c['Early_Aramaic'])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This holds the indexes of the corresponding chatacters in the c.keys()\n",
            " [503, 524]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDsRmUHlPh8P"
      },
      "source": [
        "### Saving the train tensors on disk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSi8kFq8Ph8Q"
      },
      "source": [
        "with open(os.path.join(save_path,\"train.pickle\"), \"wb\") as f:\n",
        "    pickle.dump((X,c),f)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dM6Ragq0Ph8T"
      },
      "source": [
        "### Loading the validation images into tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQRTsajiPh8T",
        "outputId": "cb6dfe1d-f8db-43b8-9398-6084747aa54f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Xval,yval,cval=loadimgs(val_folder)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading alphabet: Old_Church_Slavonic_(Cyrillic)\n",
            "loading alphabet: Mongolian\n",
            "loading alphabet: Keble\n",
            "loading alphabet: Kannada\n",
            "loading alphabet: Glagolitic\n",
            "loading alphabet: Ge_ez\n",
            "loading alphabet: Tengwar\n",
            "loading alphabet: Malayalam\n",
            "loading alphabet: Oriya\n",
            "loading alphabet: Aurek-Besh\n",
            "loading alphabet: Angelic\n",
            "loading alphabet: Gurmukhi\n",
            "loading alphabet: Atlantean\n",
            "loading alphabet: Atemayar_Qelisayer\n",
            "loading alphabet: Sylheti\n",
            "loading alphabet: ULOG\n",
            "loading alphabet: Manipuri\n",
            "loading alphabet: Syriac_(Serto)\n",
            "loading alphabet: Tibetan\n",
            "loading alphabet: Avesta\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4_6GOu5DCoh",
        "outputId": "ecda8398-eaa6-4743-d070-d2ef4e7e0637",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Xval.shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(659, 20, 105, 105)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXzUG_06Ph8W"
      },
      "source": [
        "### Saving the validation tensors on disk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuTN-hOSPh8W"
      },
      "source": [
        "with open(os.path.join(save_path,\"val.pickle\"), \"wb\") as f:\n",
        "    pickle.dump((Xval,cval),f)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ov4BrfA4Ph8c"
      },
      "source": [
        "def initialize_weights(shape, dtype=None):\n",
        "    \"\"\"\n",
        "    The paper, http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
        "    suggests to initialize CNN layer weights with mean as 0.0 and standard deviation of 0.01\n",
        "    \"\"\"\n",
        "    return np.random.normal(loc = 0.0, scale = 1e-2, size = shape)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baThgDMoPh8e"
      },
      "source": [
        "def initialize_bias(shape, dtype=None):\n",
        "    \"\"\"\n",
        "    The paper, http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
        "    suggests to initialize CNN layer bias with mean as 0.5 and standard deviation of 0.01\n",
        "    \"\"\"\n",
        "    return np.random.normal(loc = 0.5, scale = 1e-2, size = shape)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmrJ1TgiIHmY"
      },
      "source": [
        "### Siamese Networks\n",
        "![Model Architecture](https://miro.medium.com/max/2640/1*v40QXakPBOmiq4lCKbPu8w.png)\n",
        "\n",
        "The two Convolutional Neural Networks shown above are not different networks but are two copies of the same network, hence the name Siamese Networks. Basically they share the same parameters. The two input images (x1 and x2) are passed through the ConvNet to generate a fixed length feature vector for each (h(x1) and h(x2)). Assuming the neural network model is trained properly, we can make the following hypothesis: If the two input images belong to the same character, then their feature vectors must also be similar, while if the two input images belong to the different characters, then their feature vectors will also be different. Thus the element-wise absolute difference between the two feature vectors must be very different in both the above cases. And hence the similarity score generated by the output sigmoid layer must also be different in these two cases. This is the central idea behind the Siamese Networks.\n",
        "\n",
        "The `get_siamese_model()` creates the required model for implementing siamese network.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lW_IqUtuPh8h"
      },
      "source": [
        "def get_siamese_model(input_shape):\n",
        "    \"\"\"\n",
        "    Model architecture based on the one provided in: http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the tensors for the two input images\n",
        "    left_input = Input(input_shape)\n",
        "    right_input = Input(input_shape)\n",
        "    \n",
        "    # Convolutional Neural Network\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(64, (10,10), activation='relu', input_shape=input_shape,\n",
        "                   kernel_initializer=initialize_weights, kernel_regularizer=l2(2e-4)))\n",
        "    model.add(MaxPooling2D())\n",
        "    model.add(Conv2D(128, (7,7), activation='relu',\n",
        "                     kernel_initializer=initialize_weights,\n",
        "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
        "    model.add(MaxPooling2D())\n",
        "    model.add(Conv2D(128, (4,4), activation='relu', kernel_initializer=initialize_weights,\n",
        "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
        "    model.add(MaxPooling2D())\n",
        "    model.add(Conv2D(256, (4,4), activation='relu', kernel_initializer=initialize_weights,\n",
        "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='sigmoid',\n",
        "                   kernel_regularizer=l2(1e-3),\n",
        "                   kernel_initializer=initialize_weights,bias_initializer=initialize_bias))\n",
        "    \n",
        "    # Generate the encodings (feature vectors) for the two images\n",
        "    encoded_l = model(left_input)\n",
        "    encoded_r = model(right_input)\n",
        "    \n",
        "    # Add a customized layer to compute the absolute difference between the encodings\n",
        "    L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
        "    L1_distance = L1_layer([encoded_l, encoded_r])\n",
        "    \n",
        "    # Add a dense layer with a sigmoid unit to generate the similarity score\n",
        "    prediction = Dense(1,activation='sigmoid',bias_initializer=initialize_bias)(L1_distance)\n",
        "    \n",
        "    # Connect the inputs with the outputs\n",
        "    siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
        "    \n",
        "    # return the model\n",
        "    return siamese_net"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8Di-qqPPh8j",
        "outputId": "6fa1962a-7e30-43ad-a1a7-5020a3632718",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = get_siamese_model((105, 105, 1))\n",
        "model.summary()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 105, 105, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 105, 105, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_1 (Sequential)       (None, 4096)         38947648    input_3[0][0]                    \n",
            "                                                                 input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 4096)         0           sequential_1[0][0]               \n",
            "                                                                 sequential_1[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            4097        lambda[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 38,951,745\n",
            "Trainable params: 38,951,745\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTYc_TBQPh8o"
      },
      "source": [
        "optimizer = Adam(lr = 0.00006)\n",
        "model.compile(loss=\"binary_crossentropy\",optimizer=optimizer)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeUbHFsxPh8q"
      },
      "source": [
        "### Loading the train tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ie7OkZRzPh8r",
        "outputId": "3a49175c-0755-410c-945f-c773e62628ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "with open(os.path.join(save_path, \"train.pickle\"), \"rb\") as f:\n",
        "    (Xtrain, train_classes) = pickle.load(f)\n",
        "    \n",
        "print(\"Training alphabets: \\n\")\n",
        "print(list(train_classes.keys()))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training alphabets: \n",
            "\n",
            "['Hebrew', 'Armenian', 'Malay_(Jawi_-_Arabic)', 'Japanese_(katakana)', 'Anglo-Saxon_Futhorc', 'Burmese_(Myanmar)', 'Grantha', 'Asomtavruli_(Georgian)', 'Tagalog', 'Cyrillic', 'Futurama', 'Ojibwe_(Canadian_Aboriginal_Syllabics)', 'Inuktitut_(Canadian_Aboriginal_Syllabics)', 'Arcadian', 'Alphabet_of_the_Magi', 'Tifinagh', 'Early_Aramaic', 'Japanese_(hiragana)', 'Gujarati', 'Mkhedruli_(Georgian)', 'Latin', 'Balinese', 'Bengali', 'Korean', 'Greek', 'Blackfoot_(Canadian_Aboriginal_Syllabics)', 'Braille', 'Sanskrit', 'N_Ko', 'Syriac_(Estrangelo)']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkwgjsJqPh8t",
        "outputId": "64dc17d1-a8f3-4317-91cf-389074568ade",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "with open(os.path.join(save_path, \"val.pickle\"), \"rb\") as f:\n",
        "    (Xval, val_classes) = pickle.load(f)\n",
        "\n",
        "print(\"Validation alphabets:\", end=\"\\n\\n\")\n",
        "print(list(val_classes.keys()))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation alphabets:\n",
            "\n",
            "['Old_Church_Slavonic_(Cyrillic)', 'Mongolian', 'Keble', 'Kannada', 'Glagolitic', 'Ge_ez', 'Tengwar', 'Malayalam', 'Oriya', 'Aurek-Besh', 'Angelic', 'Gurmukhi', 'Atlantean', 'Atemayar_Qelisayer', 'Sylheti', 'ULOG', 'Manipuri', 'Syriac_(Serto)', 'Tibetan', 'Avesta']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXnShVZHGsTy"
      },
      "source": [
        ""
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTTJ3cZsGzOr"
      },
      "source": [
        "The input to our system will be a pair of images and the output will be a similarity score between 0 and 1.\\\n",
        "Xi = Pair of images\\\n",
        "Yi = 1 ; if both images contain the same character\\\n",
        "Yi = 0; if both images contain different characters\\\n",
        "Like following:\n",
        "\n",
        "![title](https://miro.medium.com/max/1100/1*4kfqL7aEvVMU0iALyxvG0g.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8W0uIr0He1T"
      },
      "source": [
        "We'll be creating pairs of images along with the target variable, as shown above, to be fed as input to the Siamese Network. We will generate pairs randomly from all the alphabets in the training data.\n",
        "The code to generate these pairs and targets is written in `get_batch()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoR7QHkwPh8v"
      },
      "source": [
        "def get_batch(batch_size,s=\"train\"):\n",
        "    \"\"\"\n",
        "    Create batch of n pairs, half same class, half different class\n",
        "    \"\"\"\n",
        "    if s == 'train':\n",
        "        X = Xtrain\n",
        "        categories = train_classes\n",
        "    else:\n",
        "        X = Xval\n",
        "        categories = val_classes\n",
        "    n_classes, n_examples, w, h = X.shape\n",
        "\n",
        "    # randomly sample several classes to use in the batch\n",
        "    categories = rng.choice(n_classes,size=(batch_size,),replace=False)\n",
        "    \n",
        "    # initialize 2 empty arrays for the input image batch\n",
        "    pairs=[np.zeros((batch_size, h, w,1)) for i in range(2)]\n",
        "    \n",
        "    # initialize vector for the targets\n",
        "    targets=np.zeros((batch_size,))\n",
        "    \n",
        "    # make one half of it '1's, so 2nd half of batch has same class\n",
        "    targets[batch_size//2:] = 1\n",
        "    for i in range(batch_size):\n",
        "        category = categories[i]\n",
        "        idx_1 = rng.randint(0, n_examples)\n",
        "        pairs[0][i,:,:,:] = X[category, idx_1].reshape(w, h, 1)\n",
        "        idx_2 = rng.randint(0, n_examples)\n",
        "        \n",
        "        # pick images of same class for 1st half, different for 2nd\n",
        "        if i >= batch_size // 2:\n",
        "            category_2 = category  \n",
        "        else: \n",
        "            # add a random number to the category modulo n classes to ensure 2nd image has a different category\n",
        "            category_2 = (category + rng.randint(1,n_classes)) % n_classes\n",
        "        \n",
        "        pairs[1][i,:,:,:] = X[category_2,idx_2].reshape(w, h,1)\n",
        "    \n",
        "    return pairs, targets"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJ5Wrvc-Hxwu"
      },
      "source": [
        "`get_batch()` function by passing the batch_size and it will return “batch_size” number of image pairs along with their target variables.\n",
        "We'll use it in `generate()` function to generate data in batches during the training of the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAh8sBCAPh8x"
      },
      "source": [
        "def generate(batch_size, s=\"train\"):\n",
        "    \"\"\"\n",
        "    a generator for batches, so model.fit_generator can be used. \n",
        "    \"\"\"\n",
        "    while True:\n",
        "        pairs, targets = get_batch(batch_size,s)\n",
        "        yield (pairs, targets)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZEMATjkMYPt"
      },
      "source": [
        "The model will be evaluated using **N way One shot Learning** \n",
        "\n",
        "![9 way](https://sorenbouma.github.io/images/task_9.png)\n",
        "\n",
        "In the above image, we have 9 images in the support set, and we want to find the *character* in the left exist or not, then we will compare the similarity score of the character on the left with every character in the right.\n",
        "\n",
        "The image with maximum similarity score in the support set will be the matching image.\n",
        "\n",
        "Similarly, we can do this with 36 way One shot learning, i.e increasing the support set, given as below:\n",
        "\n",
        "![25 way](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQoHaM9X0iFIg4bQCdxzPeaDcLhHKfaUxFmboDZuXCPiuvYXuqB)\n",
        "\n",
        "The code for generating N way one shot learning, is written in `make_oneshot_task()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mkf5ZDBbPh80"
      },
      "source": [
        "def make_oneshot_task(N, s=\"val\", language=None):\n",
        "    \"\"\"\n",
        "    Create pairs of test image, support set for testing N way one-shot learning. \n",
        "    \"\"\"\n",
        "    if s == 'train':\n",
        "        X = Xtrain\n",
        "        categories = train_classes\n",
        "    else:\n",
        "        X = Xval\n",
        "        categories = val_classes\n",
        "    n_classes, n_examples, w, h = X.shape\n",
        "    \n",
        "    indices = rng.randint(0, n_examples,size=(N,))\n",
        "    if language is not None: # if language is specified, select characters for that language\n",
        "        low, high = categories[language]\n",
        "        if N > high - low:\n",
        "            raise ValueError(\"This language ({}) has less than {} letters\".format(language, N))\n",
        "        categories = rng.choice(range(low,high),size=(N,),replace=False)\n",
        "\n",
        "    else: # if no language specified just pick a bunch of random letters\n",
        "        categories = rng.choice(range(n_classes),size=(N,),replace=False)            \n",
        "    true_category = categories[0]\n",
        "    ex1, ex2 = rng.choice(n_examples,replace=False,size=(2,))\n",
        "    test_image = np.asarray([X[true_category,ex1,:,:]]*N).reshape(N, w, h,1)\n",
        "    support_set = X[categories,indices,:,:]\n",
        "    support_set[0,:,:] = X[true_category,ex2]\n",
        "    support_set = support_set.reshape(N, w, h,1)\n",
        "    targets = np.zeros((N,))\n",
        "    targets[0] = 1\n",
        "    targets, test_image, support_set = shuffle(targets, test_image, support_set)\n",
        "    pairs = [test_image,support_set]\n",
        "\n",
        "    return pairs, targets"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIuw-eC8Ph84"
      },
      "source": [
        "def test_oneshot(model, N, k, s = \"val\", verbose = 0):\n",
        "    \"\"\"\n",
        "    Test average N way oneshot learning accuracy of a siamese neural net over k one-shot tasks\n",
        "    \"\"\"\n",
        "    n_correct = 0\n",
        "    if verbose:\n",
        "        print(\"Evaluating model on {} random {} way one-shot learning tasks ... \\n\".format(k,N))\n",
        "    for i in range(k):\n",
        "        inputs, targets = make_oneshot_task(N,s)\n",
        "        probs = model.predict(inputs)\n",
        "        if np.argmax(probs) == np.argmax(targets):\n",
        "            n_correct+=1\n",
        "    percent_correct = (100.0 * n_correct / k)\n",
        "    if verbose:\n",
        "        print(\"Got an average of {}% {} way one-shot learning accuracy \\n\".format(percent_correct,N))\n",
        "    return percent_correct"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhdCou-CPh8-"
      },
      "source": [
        "# Hyper parameters\n",
        "evaluate_every = 200 # interval for evaluating on one-shot tasks\n",
        "batch_size = 32\n",
        "n_iter = 20000 # No. of training iterations\n",
        "N_way = 20 # how many classes for testing one-shot tasks\n",
        "n_val = 250 # how many one-shot tasks to validate on\n",
        "best = -1"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ndjA6fcPh9A"
      },
      "source": [
        "model_path = './weights/'"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eMxyDWMPh9C",
        "outputId": "efeeeb21-e547-4e0d-8f2b-c01d8df0671a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Starting training process!\")\n",
        "print(\"-------------------------------------\")\n",
        "t_start = time.time()\n",
        "for i in range(1, n_iter+1):\n",
        "    (inputs,targets) = get_batch(batch_size)\n",
        "    loss = model.train_on_batch(inputs, targets)\n",
        "    if i % evaluate_every == 0:\n",
        "        print(\"\\n ------------- \\n\")\n",
        "        print(\"Time for {0} iterations: {1} mins\".format(i, (time.time()-t_start)/60.0))\n",
        "        print(\"Train Loss: {0}\".format(loss)) \n",
        "        val_acc = test_oneshot(model, N_way, n_val, verbose=True)\n",
        "        model.save_weights(os.path.join(model_path, 'weights.{}.h5'.format(i)))\n",
        "        if val_acc >= best:\n",
        "            print(\"Current best: {0}, previous best: {1}\".format(val_acc, best))\n",
        "            best = val_acc"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting training process!\n",
            "-------------------------------------\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 200 iterations: 0.3744197487831116 mins\n",
            "Train Loss: 2.4782845973968506\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 27.6% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 27.6, previous best: -1\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 400 iterations: 0.8163727839787801 mins\n",
            "Train Loss: 1.8820059299468994\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 44.0% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 44.0, previous best: 27.6\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 600 iterations: 1.25398192803065 mins\n",
            "Train Loss: 1.5312182903289795\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 45.2% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 45.2, previous best: 44.0\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 800 iterations: 1.6989500403404236 mins\n",
            "Train Loss: 1.2970855236053467\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 57.2% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 57.2, previous best: 45.2\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 1000 iterations: 2.1394748369852703 mins\n",
            "Train Loss: 1.126517415046692\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 58.4% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 58.4, previous best: 57.2\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 1200 iterations: 2.5890969316164654 mins\n",
            "Train Loss: 0.8834667801856995\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 52.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 1400 iterations: 3.0332858284314472 mins\n",
            "Train Loss: 0.8880666494369507\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 59.2% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 59.2, previous best: 58.4\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 1600 iterations: 3.483068021138509 mins\n",
            "Train Loss: 0.7010597586631775\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 64.4% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 64.4, previous best: 59.2\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 1800 iterations: 3.921454711755117 mins\n",
            "Train Loss: 0.8122687339782715\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 60.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 2000 iterations: 4.366502877076467 mins\n",
            "Train Loss: 0.6632964611053467\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 63.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 2200 iterations: 4.806022644042969 mins\n",
            "Train Loss: 0.6994503140449524\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 73.2% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 73.2, previous best: 64.4\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 2400 iterations: 5.248845191796621 mins\n",
            "Train Loss: 0.5924376845359802\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 64.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 2600 iterations: 5.690203936894735 mins\n",
            "Train Loss: 0.538421630859375\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 74.4% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 74.4, previous best: 73.2\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 2800 iterations: 6.132899097601572 mins\n",
            "Train Loss: 0.6252983808517456\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 68.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 3000 iterations: 6.572856080532074 mins\n",
            "Train Loss: 0.4330059885978699\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 68.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 3200 iterations: 7.018670356273651 mins\n",
            "Train Loss: 0.3920249938964844\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 66.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 3400 iterations: 7.462730034192403 mins\n",
            "Train Loss: 0.4484873414039612\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 70.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 3600 iterations: 7.91210100253423 mins\n",
            "Train Loss: 0.46998921036720276\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 73.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 3800 iterations: 8.354743460814158 mins\n",
            "Train Loss: 0.41606736183166504\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 71.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 4000 iterations: 8.797694353262584 mins\n",
            "Train Loss: 0.3674290180206299\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 70.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 4200 iterations: 9.23826369047165 mins\n",
            "Train Loss: 0.46857327222824097\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 75.2% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 75.2, previous best: 74.4\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 4400 iterations: 9.686117680867513 mins\n",
            "Train Loss: 0.359080970287323\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 69.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 4600 iterations: 10.127466265360514 mins\n",
            "Train Loss: 0.3658008575439453\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 67.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 4800 iterations: 10.570474004745483 mins\n",
            "Train Loss: 0.2981342673301697\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.4% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 78.4, previous best: 75.2\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 5000 iterations: 11.014159349600474 mins\n",
            "Train Loss: 0.34966570138931274\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 75.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 5200 iterations: 11.456676097710927 mins\n",
            "Train Loss: 0.3837696313858032\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 71.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 5400 iterations: 11.903193763891856 mins\n",
            "Train Loss: 0.30547136068344116\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 70.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 5600 iterations: 12.346761612097422 mins\n",
            "Train Loss: 0.28071215748786926\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 76.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 5800 iterations: 12.79363574186961 mins\n",
            "Train Loss: 0.2572070360183716\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 76.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 6000 iterations: 13.237260480721792 mins\n",
            "Train Loss: 0.3820232152938843\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 69.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 6200 iterations: 13.683107749621074 mins\n",
            "Train Loss: 0.28911542892456055\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 77.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 6400 iterations: 14.12526992559433 mins\n",
            "Train Loss: 0.24449817836284637\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.4% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 80.4, previous best: 78.4\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 6600 iterations: 14.56993947426478 mins\n",
            "Train Loss: 0.34249210357666016\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 73.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 6800 iterations: 15.015473965803782 mins\n",
            "Train Loss: 0.23324215412139893\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 75.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 7000 iterations: 15.462690265973409 mins\n",
            "Train Loss: 0.3247702419757843\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 73.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 7200 iterations: 15.90664215485255 mins\n",
            "Train Loss: 0.2538608908653259\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 7400 iterations: 16.356704942385356 mins\n",
            "Train Loss: 0.28140079975128174\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 75.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 7600 iterations: 16.802821719646452 mins\n",
            "Train Loss: 0.23777061700820923\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 7800 iterations: 17.25143471558889 mins\n",
            "Train Loss: 0.2332361340522766\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 8000 iterations: 17.700904210408527 mins\n",
            "Train Loss: 0.2269306480884552\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 77.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 8200 iterations: 18.15286318063736 mins\n",
            "Train Loss: 0.2324446737766266\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 79.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 8400 iterations: 18.59910443623861 mins\n",
            "Train Loss: 0.20556865632534027\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 84.4% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 84.4, previous best: 80.4\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 8600 iterations: 19.04892973502477 mins\n",
            "Train Loss: 0.49369895458221436\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 72.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 8800 iterations: 19.493104422092436 mins\n",
            "Train Loss: 0.3013216257095337\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 74.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 9000 iterations: 19.946102698644 mins\n",
            "Train Loss: 0.21722567081451416\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 9200 iterations: 20.396555634339652 mins\n",
            "Train Loss: 0.2798343300819397\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 76.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 9400 iterations: 20.84658202727636 mins\n",
            "Train Loss: 0.33396798372268677\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 77.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 9600 iterations: 21.29343401193619 mins\n",
            "Train Loss: 0.2162032574415207\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 74.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 9800 iterations: 21.747392626603446 mins\n",
            "Train Loss: 0.18040922284126282\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 10000 iterations: 22.19505783319473 mins\n",
            "Train Loss: 0.212692528963089\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 10200 iterations: 22.644289509455362 mins\n",
            "Train Loss: 0.2273138463497162\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 77.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 10400 iterations: 23.091113503774007 mins\n",
            "Train Loss: 0.2119486778974533\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 81.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 10600 iterations: 23.542519092559814 mins\n",
            "Train Loss: 0.20597830414772034\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 77.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 10800 iterations: 23.988059345881144 mins\n",
            "Train Loss: 0.17575812339782715\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 11000 iterations: 24.439941732088723 mins\n",
            "Train Loss: 0.1812237799167633\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 75.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 11200 iterations: 24.88415822585424 mins\n",
            "Train Loss: 0.34418052434921265\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 70.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 11400 iterations: 25.335756548245747 mins\n",
            "Train Loss: 0.26127368211746216\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 11600 iterations: 25.780572621027627 mins\n",
            "Train Loss: 0.16754800081253052\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 11800 iterations: 26.23278603553772 mins\n",
            "Train Loss: 0.18993109464645386\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 12000 iterations: 26.69128382205963 mins\n",
            "Train Loss: 0.24812740087509155\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 12200 iterations: 27.148582859834036 mins\n",
            "Train Loss: 0.16638979315757751\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 12400 iterations: 27.602232174078623 mins\n",
            "Train Loss: 0.215814471244812\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 73.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 12600 iterations: 28.05361085732778 mins\n",
            "Train Loss: 0.239047110080719\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 76.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 12800 iterations: 28.513252675533295 mins\n",
            "Train Loss: 0.19272148609161377\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 82.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 13000 iterations: 28.963299949963886 mins\n",
            "Train Loss: 0.2036363035440445\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 74.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 13200 iterations: 29.412746437390645 mins\n",
            "Train Loss: 0.1622183918952942\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 13400 iterations: 29.86347686847051 mins\n",
            "Train Loss: 0.1762736439704895\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 13600 iterations: 30.313085075219472 mins\n",
            "Train Loss: 0.21741005778312683\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 79.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 13800 iterations: 30.758873709042867 mins\n",
            "Train Loss: 0.1710970103740692\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 76.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 14000 iterations: 31.209968388080597 mins\n",
            "Train Loss: 0.2350052446126938\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 14200 iterations: 31.656521761417387 mins\n",
            "Train Loss: 0.17366530001163483\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 14400 iterations: 32.10544081926346 mins\n",
            "Train Loss: 0.1709238588809967\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 14600 iterations: 32.552540417512255 mins\n",
            "Train Loss: 0.21535605192184448\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 14800 iterations: 33.002589309215544 mins\n",
            "Train Loss: 0.377827912569046\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 83.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 15000 iterations: 33.451191278298694 mins\n",
            "Train Loss: 0.20628981292247772\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 15200 iterations: 33.90251578489939 mins\n",
            "Train Loss: 0.1471674144268036\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 15400 iterations: 34.34728167851766 mins\n",
            "Train Loss: 0.23731771111488342\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 82.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 15600 iterations: 34.79660493135452 mins\n",
            "Train Loss: 0.21436026692390442\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 81.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 15800 iterations: 35.24594324032466 mins\n",
            "Train Loss: 0.18395939469337463\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 16000 iterations: 35.69287273089091 mins\n",
            "Train Loss: 0.26588380336761475\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 16200 iterations: 36.13640826145808 mins\n",
            "Train Loss: 0.17118442058563232\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 83.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 16400 iterations: 36.58688715696335 mins\n",
            "Train Loss: 0.16083800792694092\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 82.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 16600 iterations: 37.034076205889384 mins\n",
            "Train Loss: 0.2596246004104614\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 81.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 16800 iterations: 37.48420519828797 mins\n",
            "Train Loss: 0.1846703290939331\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 77.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 17000 iterations: 37.93247734705607 mins\n",
            "Train Loss: 0.17416298389434814\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 17200 iterations: 38.38330219984054 mins\n",
            "Train Loss: 0.3190046548843384\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 17400 iterations: 38.83101712067922 mins\n",
            "Train Loss: 0.17787644267082214\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 76.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 17600 iterations: 39.28084468046824 mins\n",
            "Train Loss: 0.19600079953670502\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 17800 iterations: 39.72537109057109 mins\n",
            "Train Loss: 0.16549454629421234\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 82.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 18000 iterations: 40.17320181131363 mins\n",
            "Train Loss: 0.17881399393081665\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 82.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 18200 iterations: 40.620315905412035 mins\n",
            "Train Loss: 0.16263052821159363\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 18400 iterations: 41.067636624972025 mins\n",
            "Train Loss: 0.14848187565803528\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 82.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 18600 iterations: 41.51437776486079 mins\n",
            "Train Loss: 0.15378496050834656\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 83.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 18800 iterations: 41.96554997762044 mins\n",
            "Train Loss: 0.13368482887744904\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 19000 iterations: 42.412320764859516 mins\n",
            "Train Loss: 0.14723235368728638\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 19200 iterations: 42.8609507838885 mins\n",
            "Train Loss: 0.2035273015499115\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 81.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 19400 iterations: 43.31180563370387 mins\n",
            "Train Loss: 0.18587106466293335\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 19600 iterations: 43.76771302223206 mins\n",
            "Train Loss: 0.15623973309993744\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 85.2% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 85.2, previous best: 84.4\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 19800 iterations: 44.216167291005455 mins\n",
            "Train Loss: 0.1582830548286438\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 20000 iterations: 44.6663303176562 mins\n",
            "Train Loss: 0.26651930809020996\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 82.0% 20 way one-shot learning accuracy \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AW_gFOU0Ph9G"
      },
      "source": [
        "### Load model weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "596evBkxPh9H"
      },
      "source": [
        "model.load_weights(os.path.join(model_path, \"weights.20000.h5\"))"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5jpFvoWPh9I"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sBLjkCWPh9Q"
      },
      "source": [
        "ways = np.arange(1,20,2)\n",
        "trials = 50"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVXAFzGJPh9T",
        "outputId": "bf7ad159-b566-4180-d138-d35637568882",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "val_accs, train_accs = [], []\n",
        "for N in ways:    \n",
        "    val_accs.append(test_oneshot(model, N, trials, \"val\", verbose=True))\n",
        "    train_accs.append(test_oneshot(model, N, trials, \"train\", verbose=True))\n",
        "    print(\"---------------------------------------------------------------------------------------------------------------\")"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating model on 50 random 1 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 100.0% 1 way one-shot learning accuracy \n",
            "\n",
            "Evaluating model on 50 random 1 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 100.0% 1 way one-shot learning accuracy \n",
            "\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "Evaluating model on 50 random 3 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 96.0% 3 way one-shot learning accuracy \n",
            "\n",
            "Evaluating model on 50 random 3 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 100.0% 3 way one-shot learning accuracy \n",
            "\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "Evaluating model on 50 random 5 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 100.0% 5 way one-shot learning accuracy \n",
            "\n",
            "Evaluating model on 50 random 5 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 100.0% 5 way one-shot learning accuracy \n",
            "\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "Evaluating model on 50 random 7 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 96.0% 7 way one-shot learning accuracy \n",
            "\n",
            "Evaluating model on 50 random 7 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 98.0% 7 way one-shot learning accuracy \n",
            "\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "Evaluating model on 50 random 9 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 90.0% 9 way one-shot learning accuracy \n",
            "\n",
            "Evaluating model on 50 random 9 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 98.0% 9 way one-shot learning accuracy \n",
            "\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "Evaluating model on 50 random 11 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 94.0% 11 way one-shot learning accuracy \n",
            "\n",
            "Evaluating model on 50 random 11 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 98.0% 11 way one-shot learning accuracy \n",
            "\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "Evaluating model on 50 random 13 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 84.0% 13 way one-shot learning accuracy \n",
            "\n",
            "Evaluating model on 50 random 13 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 96.0% 13 way one-shot learning accuracy \n",
            "\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "Evaluating model on 50 random 15 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 90.0% 15 way one-shot learning accuracy \n",
            "\n",
            "Evaluating model on 50 random 15 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 94.0% 15 way one-shot learning accuracy \n",
            "\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "Evaluating model on 50 random 17 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.0% 17 way one-shot learning accuracy \n",
            "\n",
            "Evaluating model on 50 random 17 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 94.0% 17 way one-shot learning accuracy \n",
            "\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "Evaluating model on 50 random 19 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 86.0% 19 way one-shot learning accuracy \n",
            "\n",
            "Evaluating model on 50 random 19 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 94.0% 19 way one-shot learning accuracy \n",
            "\n",
            "---------------------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voqtETauPh9W"
      },
      "source": [
        "### Save the accuracies on disk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ce4KkouPh9X"
      },
      "source": [
        "with open(os.path.join(save_path,\"accuracies.pickle\"), \"wb\") as f:\n",
        "    pickle.dump((val_accs,train_accs),f)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JVzgzJ0Ph9Z"
      },
      "source": [
        "### Load the accuracies from disk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2gjQPGpPh9a"
      },
      "source": [
        "with open(os.path.join(save_path, \"accuracies.pickle\"), \"rb\") as f:\n",
        "    (val_accs, train_accs) = pickle.load(f)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcqy4StUPh9b"
      },
      "source": [
        "### Below two functions are used for visualizing test image and support set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ju6ECIc_Ph9c"
      },
      "source": [
        "def concat_images(X):\n",
        "    \"\"\"\n",
        "    Concatenates a bunch of images into a big matrix for plotting purposes.\n",
        "    \"\"\"\n",
        "    nc, h , w, _ = X.shape\n",
        "    X = X.reshape(nc, h, w)\n",
        "    n = np.ceil(np.sqrt(nc)).astype(\"int8\")\n",
        "    img = np.zeros((n*w,n*h))\n",
        "    x = 0\n",
        "    y = 0\n",
        "    for example in range(nc):\n",
        "        img[x*w:(x+1)*w,y*h:(y+1)*h] = X[example]\n",
        "        y += 1\n",
        "        if y >= n:\n",
        "            y = 0\n",
        "            x += 1\n",
        "    return img"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEK81GYDPh9e"
      },
      "source": [
        "def plot_oneshot_task(pairs):\n",
        "    fig,(ax1,ax2) = plt.subplots(nrows=1, ncols=2)\n",
        "    ax1.matshow(pairs[0][0].reshape(105,105), cmap='gray')\n",
        "    img = concat_images(pairs[1])\n",
        "    ax1.get_yaxis().set_visible(False)\n",
        "    ax1.get_xaxis().set_visible(False)\n",
        "    ax2.matshow(img,cmap='gray')\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.show()"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BYxcBUNPh9h",
        "outputId": "f3f859d2-b7c9-466b-a9ee-5c15d1838707",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "# Example of concat image visualization\n",
        "pairs, targets = make_oneshot_task(16,\"train\",\"Sanskrit\")\n",
        "plot_oneshot_task(pairs)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyshEnsDPh9j"
      },
      "source": [
        "### Resuts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZNXmnYBPh9j",
        "outputId": "08795351-aaa8-4b6e-ba17-c8779d461136",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        }
      },
      "source": [
        "fig,ax = plt.subplots(1)\n",
        "ax.plot(ways, val_accs, \"m\", label=\"Siamese(val set)\")\n",
        "ax.plot(ways, train_accs, \"y\", label=\"Siamese(train set)\")\n",
        "plt.xlabel(\"Number of possible classes in one-shot tasks\")\n",
        "plt.ylabel(\"% Accuracy\")\n",
        "plt.title(\"Omiglot One-Shot Learning Performance of a Siamese Network\")\n",
        "box = ax.get_position()\n",
        "ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
        "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "inputs,targets = make_oneshot_task(20, \"val\", 'Oriya')\n",
        "plt.show()\n",
        "\n",
        "plot_oneshot_task(inputs)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_E3-lTdyPh9l",
        "outputId": "f5b0b271-caf6-4085-9d82-4a5142960c60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Accuracy\n",
        "sum(val_accs)/len(val_accs)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "91.6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    }
  ]
}